"""Module for comparing outputs of two versions of the algoritmus."""

import dataclasses
import logging
import shutil
import subprocess
import sys
from pathlib import Path

import pandas as pd

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

REPO_URL = "https://github.com/Institut-zdravotnych-analyz/OSN-Algoritmus-MS.git"
CLONED_REPO_DIR = Path("OSN-Algoritmus-MS")


@dataclasses.dataclass
class RunConfig:
    """Configuration for a single run.

    Args:
        source: Either "local" to use the locally installed version, or a git ref.
        identifier: Identifier for the version configuration.
        csv_delimiter: Delimiter for the input/output CSV files.
        input_path: Path to the input file.
        init_output_path: Optional path for the output file. If None, it's generated
                          based on the input_path.
        flags: List of command line flags to pass to the algoritmus.

    Attributes:
        output_path: Path to the output file, resolved and guaranteed to be set after initialization.

    """

    source: str
    identifier: str
    csv_delimiter: str
    input_path: Path
    flags: list[str] = dataclasses.field(default_factory=list)

    def __post_init__(self) -> None:
        """Resolve input_path and set output_path."""
        self.input_path = self.input_path.resolve()


def create_output_path(input_path: Path) -> Path:
    """Create an output path based on the input path, the same way as the algoritmus does."""
    return input_path.with_stem(f"{input_path.stem}_output")


def run_algoritmus_from_ref(run_cfg: RunConfig) -> Path:
    """Run the algoritmus from a specific git ref.

    Args:
        run_cfg: Configuration for the run

    Returns:
        Path to the output file generated by the algoritmus

    """
    logger.info(f"Checking out and running version from ref: {run_cfg.source} with flags: {run_cfg.flags}")

    if not CLONED_REPO_DIR.exists():
        logger.info("Cloning repo")
        clone_repo = ["git", "clone", REPO_URL]
        subprocess.run(clone_repo, check=True, capture_output=True)

    ref = run_cfg.source

    fetch_ref_cmd = ["git", "-C", str(CLONED_REPO_DIR), "fetch", "origin", ref]
    subprocess.run(fetch_ref_cmd, check=True, capture_output=True)
    checkout_ref_cmd = ["git", "-C", str(CLONED_REPO_DIR), "checkout", ref]
    subprocess.run(checkout_ref_cmd, check=True, capture_output=True)

    setup_py_exists = (CLONED_REPO_DIR / "setup.py").exists()
    pyproject_toml_exists = (CLONED_REPO_DIR / "pyproject.toml").exists()
    is_pkg = setup_py_exists or pyproject_toml_exists

    if is_pkg:
        venv_dir = CLONED_REPO_DIR / "venv_dir"
        logger.info("Installing package")
        if not venv_dir.exists():
            create_venv = [sys.executable, "-m", "venv", str(venv_dir)]
            subprocess.run(create_venv, cwd=CLONED_REPO_DIR, check=True, capture_output=True)
        install_pkg = [str(venv_dir / "bin" / "pip"), "install", "."]
        subprocess.run(install_pkg, cwd=CLONED_REPO_DIR, check=True, capture_output=True)
        run_algo = [
            str(venv_dir / "bin" / "python"),
            "-m",
            "osn_algoritmus",
            str(run_cfg.input_path),
            *run_cfg.flags,
        ]
    else:
        run_algo = [sys.executable, "main.py", str(run_cfg.input_path), *run_cfg.flags]

    logger.info(f"Running algoritmus with command: {' '.join(run_algo)}")
    subprocess.run(run_algo, cwd=CLONED_REPO_DIR, check=True)
    return create_output_path(run_cfg.input_path)


def run_algoritmus_from_local(run_cfg: RunConfig) -> Path:
    """Run the locally installed version of the algoritmus.

    Args:
        run_cfg: Configuration for the run

    Returns:
        Path to the output file generated by the algoritmus

    """
    from osn_algoritmus.core import process_csv
    from osn_algoritmus.utils import setup_parser

    logger.info(f"Running local version with flags: {run_cfg.flags}")

    parser = setup_parser(vsetky_vykony_hlavne=True, vyhodnot_neuplne_pripady=True, ponechaj_duplicity=True)
    args = parser.parse_args(run_cfg.flags)

    process_csv(
        run_cfg.input_path,
        all_vykony_hlavne=args.vsetky_vykony_hlavne,
        evaluate_incomplete_pripady=args.vyhodnot_neuplne_pripady,
        allow_duplicates=args.ponechaj_duplicity,
    )
    return create_output_path(run_cfg.input_path)


def compare_outputs(
    df_a: pd.DataFrame,
    df_b: pd.DataFrame,
    run_a_identifier: str,
    run_b_identifier: str,
) -> pd.DataFrame:
    """Compare outputs from two different runs of the algoritmus.

    Args:
        df_a: DataFrame from run A
        df_b: DataFrame from run B
        run_a_identifier: Identifier for run A
        run_b_identifier: Identifier for run B

    Returns:
        DataFrame containing only the rows where the outputs differ

    """
    merged_df = df_a.merge(
        df_b[["id", "ms"]],
        on="id",
        suffixes=(f"_{run_a_identifier}", f"_{run_b_identifier}"),
    )

    return merged_df.loc[merged_df[f"ms_{run_a_identifier}"] != merged_df[f"ms_{run_b_identifier}"]]


def run_algoritmus(run_cfg: RunConfig) -> Path:
    """Run algoritmus based on the configuration."""
    if run_cfg.source == "local":
        return run_algoritmus_from_local(run_cfg)
    return run_algoritmus_from_ref(run_cfg)


def run_and_compare(
    run_a_cfg: RunConfig,
    run_b_cfg: RunConfig,
    *,
    remove_repo: bool = True,
) -> pd.DataFrame:
    """Run the algoritmus with two different versions and compare their outputs.

    Args:
        run_a_cfg: Configuration for the first run
        run_b_cfg: Configuration for the second run
        remove_repo: If True, remove the cloned repository after running the algoritmus
    Returns:
        DataFrame with algoritmus outputs containing only the rows where the outputs
        differ

    """
    if run_a_cfg.identifier == run_b_cfg.identifier:
        msg = "Version identifiers need to be different"
        raise ValueError(msg)

    needs_repo_cleanup = (run_a_cfg.source != "local" or run_b_cfg.source != "local") and remove_repo

    created_files = set()
    try:
        output_a_path = run_algoritmus(run_a_cfg)
        df_a = pd.read_csv(output_a_path, sep=run_a_cfg.csv_delimiter)
        created_files.add(output_a_path)

        output_b_path = run_algoritmus(run_b_cfg)
        df_b = pd.read_csv(output_b_path, sep=run_b_cfg.csv_delimiter)
        created_files.add(output_b_path)

        differences = compare_outputs(df_a, df_b, run_a_cfg.identifier, run_b_cfg.identifier)

    finally:
        if needs_repo_cleanup and CLONED_REPO_DIR.exists():
            logger.info(f"Removing cloned repository at {CLONED_REPO_DIR.resolve()}")
            shutil.rmtree(CLONED_REPO_DIR)

        logger.info("Cleaning up created files")
        for file_path in created_files:
            if file_path and file_path.exists():
                file_path.unlink()

    return differences
